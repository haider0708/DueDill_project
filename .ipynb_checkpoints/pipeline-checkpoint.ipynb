{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff41745-2174-4a9f-9e26-73505aa33d1e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Pipeline Contart Verifiée : Récupération et Traitement des Données</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e2fd1-4eb5-4bdb-b38b-b3f16f5c6b46",
   "metadata": {},
   "source": [
    "\n",
    "Ce pipeline a pour objectif de récupérer les contrats verifiés (Un contrat validé sur Etherscan  contient généralement des informations essentielles\n",
    "permettant d en évaluer la sécurité, la transparence, et la fonctionnalité. La vérification du contrat assure que le code est visible, \n",
    "ce qui permet aux utilisateurs de vérifier son comportement et de s assurer qu il ne contient pas de vulnérabilités)\n",
    "**Étapes du pipeline :**\n",
    "1. Récupération des données depuis Etherscan\n",
    "2. Exportation des données brutes vers MongoDB.\n",
    "3. Importation des données depuis MongoDB.\n",
    "4. Nettoyage des données.\n",
    "5. Exportation des données nettoyées vers MongoDB.\n",
    "6. Compréhension des données (Data Understanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d47cc-4d0e-4913-b4ff-a3e4432e6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cc6e1-a807-4dca-b60c-18caceac3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pymongo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166b333-d970-41f4-930f-9f0cb7fe6eb8",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Connexion à la Base de Données MongoDB Partagée</h1>\n",
    "Configuration de la Connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb02d0c3-0684-45f1-bd0e-e563890e896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOURA\\anaconda3\\Lib\\site-packages\\pymongo\\pyopenssl_context.py:355: CryptographyDeprecationWarning: Parsed a negative serial number, which is disallowed by RFC 5280. Loading this certificate will cause an exception in the next release of cryptography.\n",
      "  _crypto.X509.from_cryptography(x509.load_der_x509_certificate(cert))\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Chaîne de connexion à MongoDB\n",
    "connection_string = \"mongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/\"\n",
    "\n",
    "# Connexion au client MongoDB\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Accéder à la base de données \"due_diligence\"\n",
    "db = client.due_diligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a402ee-c428-44b6-b5cc-784845d75ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(connection_string , tls=True, tlsAllowInvalidCertificates=True)\n",
    "db = client[\"due_diligence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa28e75f-f391-411e-b768-177492046e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion réussie à MongoDB Atlas !\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "connection_string = \"mongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/\"\n",
    "\n",
    "try:\n",
    "    client = pymongo.MongoClient(connection_string, serverSelectionTimeoutMS=5000, tls=True)\n",
    "    db = client.test\n",
    "    print(\"Connexion réussie à MongoDB Atlas !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9645996-e3be-43d7-a9a3-4d7ef34a389c",
   "metadata": {},
   "source": [
    "## Récupération des Données\n",
    "Cette première étape présente la récupération des données : des contrats intelligents vérifiés sur Etherscan.\n",
    " Nous récupérons les données depuis :\n",
    "- **Etherscan** : Etherscan est un explorateur de blocs et un service d'analyse pour la blockchain Ethereum. Il permet aux utilisateurs de visualiser les transactions, les contrats intelligents (smart contracts), les adresses Ethereum et les informations relatives à la blockchain d'Ethereum en temps réel.\n",
    "\n",
    "Les données sont récupérées via la méthode web scrapping et stockées dans des variables pour un traitement ultérieur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa78aa1c-5ef7-45a3-ba50-4157922a15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping : https://etherscan.io/contractsVerified\n",
      "Page suivante : https://etherscan.io/contractsVerified/2\n",
      "Scraping : https://etherscan.io/contractsVerified/2\n",
      "Page suivante : https://etherscan.io/contractsVerified/3\n",
      "Scraping : https://etherscan.io/contractsVerified/3\n",
      "Page suivante : https://etherscan.io/contractsVerified/4\n",
      "Scraping : https://etherscan.io/contractsVerified/4\n",
      "Page suivante : https://etherscan.io/contractsVerified/5\n",
      "Scraping : https://etherscan.io/contractsVerified/5\n",
      "Page suivante : https://etherscan.io/contractsVerified/6\n",
      "Scraping : https://etherscan.io/contractsVerified/6\n",
      "Page suivante : https://etherscan.io/contractsVerified/7\n",
      "Scraping : https://etherscan.io/contractsVerified/7\n",
      "Page suivante : https://etherscan.io/contractsVerified/8\n",
      "Scraping : https://etherscan.io/contractsVerified/8\n",
      "Page suivante : https://etherscan.io/contractsVerified/9\n",
      "Scraping : https://etherscan.io/contractsVerified/9\n",
      "Page suivante : https://etherscan.io/contractsVerified/10\n",
      "Scraping : https://etherscan.io/contractsVerified/10\n",
      "Page suivante : https://etherscan.io/contractsVerified/11\n",
      "Scraping : https://etherscan.io/contractsVerified/11\n",
      "Page suivante : https://etherscan.io/contractsVerified/12\n",
      "Scraping : https://etherscan.io/contractsVerified/12\n",
      "Page suivante : https://etherscan.io/contractsVerified/13\n",
      "Scraping : https://etherscan.io/contractsVerified/13\n",
      "Page suivante : https://etherscan.io/contractsVerified/14\n",
      "Scraping : https://etherscan.io/contractsVerified/14\n",
      "Page suivante : https://etherscan.io/contractsVerified/15\n",
      "Scraping : https://etherscan.io/contractsVerified/15\n",
      "Page suivante : https://etherscan.io/contractsVerified/16\n",
      "Scraping : https://etherscan.io/contractsVerified/16\n",
      "Page suivante : https://etherscan.io/contractsVerified/17\n",
      "Scraping : https://etherscan.io/contractsVerified/17\n",
      "Page suivante : https://etherscan.io/contractsVerified/18\n",
      "Scraping : https://etherscan.io/contractsVerified/18\n",
      "Page suivante : https://etherscan.io/contractsVerified/19\n",
      "Scraping : https://etherscan.io/contractsVerified/19\n",
      "Page suivante : https://etherscan.io/contractsVerified/20\n",
      "Scraping : https://etherscan.io/contractsVerified/20\n",
      "Données sauvegardées dans smart_contracts.json\n"
     ]
    }
   ],
   "source": [
    "# En-têtes HTTP pour simuler un navigateur réel\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Fonction pour vérifier si le scraping est bloqué\n",
    "def is_scraping_blocked(response_text):\n",
    "    \"\"\"Vérifie si la page contient des éléments indiquant un blocage (ex: Cloudflare, CAPTCHA).\"\"\"\n",
    "    keywords = [\"are you a human\", \"captcha\", \"Cloudflare\", \"access denied\"]\n",
    "    return any(keyword.lower() in response_text.lower() for keyword in keywords)\n",
    "\n",
    "# Fonction pour convertir une date\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Convertit une date sous forme de texte en format datetime.\"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")  # Adapter le format si nécessaire\n",
    "    except ValueError:\n",
    "        return \"Non Vérifié\"\n",
    "\n",
    "# Fonction pour extraire les contrats d'une page\n",
    "def extract_contracts(page_url):\n",
    "    \"\"\"Scrape une page et extrait les contrats.\"\"\"\n",
    "    print(f\"Scraping : {page_url}\")\n",
    "\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        if is_scraping_blocked(response.text):\n",
    "            print(\"Scraping détecté comme bloqué. Attente de 10 secondes avant réessai...\")\n",
    "            time.sleep(10)\n",
    "            return extract_contracts(page_url)  # Réessayer après un délai\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Trouver les lignes de contrat\n",
    "        rows = soup.find_all('tr')\n",
    "\n",
    "        # Extraire les données de chaque ligne\n",
    "        contracts = []\n",
    "        for row in rows[1:]:  # Ignorer l'en-tête\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                contract_address = cols[0].text.strip()  # Adresse du contrat\n",
    "                contract_name = cols[1].text.strip()  # Nom du contrat\n",
    "                compiler_version = cols[3].text.strip()  # Version du compilateur\n",
    "                balance = cols[4].text.strip() if len(cols) > 4 else \"N/A\"  # Équilibre\n",
    "                \n",
    "                # Convertir la date de vérification\n",
    "                verified = parse_date(cols[5].text.strip()) if len(cols) > 5 else \"Non Vérifié\"\n",
    "                \n",
    "                # Ajouter le contrat à la liste\n",
    "                contracts.append({\n",
    "                    \"Adresse\": contract_address,\n",
    "                    \"Nom du contrat\": contract_name,\n",
    "                    \"Version\": compiler_version,\n",
    "                    \"Équilibre\": balance,\n",
    "                    \"Vérifié\": verified,\n",
    "                    \"Date_Extraction\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Format standard\n",
    "                })\n",
    "        \n",
    "        # Gérer la pagination\n",
    "        next_page = soup.find('a', {'aria-label': 'Next'})\n",
    "        if next_page:\n",
    "            next_url = \"https://etherscan.io\" + next_page['href']\n",
    "            print(f\"Page suivante : {next_url}\")\n",
    "            contracts.extend(extract_contracts(next_url))  # Récupérer les contrats des pages suivantes\n",
    "            \n",
    "        return contracts\n",
    "    else:\n",
    "        print(f\" Erreur {response.status_code} lors de la récupération de la page {page_url}\")\n",
    "        return []\n",
    "\n",
    "# Fonction pour sauvegarder les contrats dans un fichier JSON\n",
    "def save_to_json(data, filename=\"smart_contracts.json\"):\n",
    "    \"\"\"Enregistre les contrats dans un fichier JSON.\"\"\"\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Données sauvegardées dans {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'enregistrement du fichier : {e}\")\n",
    "\n",
    "# Test de la fonction\n",
    "url = \"https://etherscan.io/contractsVerified\"\n",
    "smart_contracts = extract_contracts(url)\n",
    "\n",
    "# Enregistrer les contrats dans un fichier JSON\n",
    "if smart_contracts:\n",
    "    save_to_json(smart_contracts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c86fc-6398-41fe-bed1-7161e683cde7",
   "metadata": {},
   "source": [
    "## Exportation des données brutes vers MongoDB\n",
    "Une fois les contrats extraits , on passe à les enregistrer directement dans MongoDB.Cela permet de conserver une trace des données brutes avant tout traitement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f007db0f-a1df-47bc-9769-1ffef2057015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\noura\\anaconda3\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\noura\\anaconda3\\lib\\site-packages (from pymongo) (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf0f884-434c-49d0-95c3-745faea8a8d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ssl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m connection_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/?tlsAllowInvalidCertificates=true\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Connexion au client MongoDB\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m client \u001b[38;5;241m=\u001b[39m MongoClient(connection_string,ssl_cert_reqs\u001b[38;5;241m=\u001b[39mssl\u001b[38;5;241m.\u001b[39mCERT_NONE)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Accéder à la base de données \"due_diligence\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m db \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdue_diligence\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ssl' is not defined"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Chaîne de connexion avec option désactivant la validation SSL\n",
    "connection_string = \"mongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/?tlsAllowInvalidCertificates=true\"\n",
    "\n",
    "# Connexion au client MongoDB\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Accéder à la base de données \"due_diligence\"\n",
    "db = client.due_diligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b4de023-1c17-4c49-b3c3-b7b6dd1197cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'exportation vers MongoDB : SSL handshake failed: cluster0-shard-00-02.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: cluster0-shard-00-01.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: cluster0-shard-00-00.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 67cec4dd6a402a83bc720faf, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.6pqb0.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect(\"SSL handshake failed: cluster0-shard-00-00.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)\")>, <ServerDescription ('cluster0-shard-00-01.6pqb0.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect(\"SSL handshake failed: cluster0-shard-00-01.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)\")>, <ServerDescription ('cluster0-shard-00-02.6pqb0.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect(\"SSL handshake failed: cluster0-shard-00-02.6pqb0.mongodb.net:27017: [('SSL routines', '', 'tlsv1 alert internal error')] (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)\")>]>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def export_to_mongodb_from_json(file_path, collection_name):\n",
    "    \"\"\"\n",
    "    Exporte les données d'un fichier JSON vers une base de données MongoDB.\n",
    "    \n",
    "    :param file_path: Chemin du fichier JSON à importer.\n",
    "    :param collection_name: Nom de la collection MongoDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Charger les données du fichier JSON\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Connexion à MongoDB\n",
    "        connection_string = \"mongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/?tlsAllowInvalidCertificates=true\"\n",
    "        client = MongoClient(connection_string)\n",
    "\n",
    "        # Accéder à la collection\n",
    "        db = client.due_diligence\n",
    "        collection = db[collection_name]\n",
    "\n",
    "        # Insérer les données dans la collection MongoDB\n",
    "        if isinstance(data, list):\n",
    "            collection.insert_many(data)\n",
    "        else:\n",
    "            collection.insert_one(data)\n",
    "\n",
    "        print(f\"Données exportées vers MongoDB dans la collection {collection_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exportation vers MongoDB : {e}\")\n",
    "\n",
    "# Exemple d'appel de la fonction\n",
    "export_to_mongodb_from_json('smart_contracts.json', 'smart_contracts_raw')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4254b-9568-49bc-a8c8-19eca02c9fef",
   "metadata": {},
   "source": [
    "## Importation des données brutes depuis MongoDB partagée\n",
    "Les données brutes sont réimportées depuis MongoDB pour être nettoyées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c6a0e-c228-45aa-a4d1-3a6f51d0a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour importer des données depuis MongoDB\n",
    "def import_from_mongodb(collection_name):\n",
    "    try:\n",
    "        # Accéder à la collection MongoDB\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Récupérer toutes les données de la collection\n",
    "        data = list(collection.find())  # Utilisation de find() pour récupérer les données\n",
    "        \n",
    "        # Enlever l'ID MongoDB par défaut si nécessaire\n",
    "        for record in data:\n",
    "            record.pop('_id', None)  # Supprime l'attribut _id généré automatiquement par MongoDB\n",
    "        \n",
    "        if data:\n",
    "            print(f\"{len(data)} données importées depuis MongoDB dans la collection {collection_name}\")\n",
    "        else:\n",
    "            print(f\"Aucune donnée trouvée dans la collection {collection_name}.\")\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'importation depuis MongoDB : {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3d124-f7f3-4900-b3ea-67b97def3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les données depuis MongoDB\n",
    "contracts_data_from_mongo = import_from_mongodb('contracts_raw_data')\n",
    "\n",
    "# Afficher un exemple des données importées\n",
    "print(contracts_data_from_mongo[:2])  # Afficher les deux premières entrées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046324c2-0cd6-456e-9674-e52ee7d09e9d",
   "metadata": {},
   "source": [
    "## Nettoyage des Données\n",
    "L'objectif de cette étape est de s'assurer que les données récupérées sont propres et prêtes à être utilisées dans des analyses ou des processus futurs. Le nettoyage inclut des actions comme :\n",
    "- Gestion des valeurs manquantes : Remplacer ou supprimer les valeurs nulles.\n",
    "- Suppression des doublons : Si plusieurs enregistrements identiques existent.\n",
    "- Conversion des types de données : Assurer que les types de données sont corrects (par exemple, convertir les chaînes de caractères en nombres si nécessaire).\n",
    "- Nettoyage des colonnes inutiles : Supprimer des colonnes ou des informations non pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c6deb-b7a8-475b-a092-70f8440e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de nettoyage des données\n",
    "def clean_data(data):\n",
    "    # Convertir les données en DataFrame pour faciliter le nettoyage\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Suppression des doublons\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Suppression des colonnes inutiles (exemple : si tu as une colonne 'Date_Extraction' que tu ne souhaites pas)\n",
    "    df.drop(columns=['Date_Extraction'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Remplacer les valeurs manquantes (par exemple, remplacer par 'N/A' ou par une valeur par défaut)\n",
    "    df.fillna('N/A', inplace=True)\n",
    "\n",
    "    # S'assurer que les types de données sont corrects (par exemple, la colonne \"Équilibre\" doit être un nombre)\n",
    "    df['Équilibre'] = pd.to_numeric(df['Équilibre'], errors='coerce')  # Convertir en nombre, NaN si non convertible\n",
    "\n",
    "    # Encodage de la colonne \"Vérifié\" : 'Oui' -> 1, 'Non' -> 0\n",
    "    df['Vérifié'] = df['Vérifié'].map({'Oui': 1, 'Non': 0}).fillna('N/A')  # Remplacer NaN si nécessaire\n",
    "\n",
    "    # D'autres transformations de nettoyage peuvent être ajoutées ici\n",
    "\n",
    "    # Retourner les données nettoyées\n",
    "    return df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "contracts_data = import_from_mongodb('contracts_raw_data')\n",
    "cleaned_data = clean_data(contracts_data)\n",
    "\n",
    "# Afficher les données nettoyées\n",
    "print(cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a5860-340b-4ed9-89a7-52a9e412a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cleaned_data(df):\n",
    "    # Vérifier si les données sont prêtes\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(\"Des valeurs manquantes subsistent.\")\n",
    "    else:\n",
    "        print(\"Les données sont prêtes pour l'exportation.\")\n",
    "\n",
    "# Validation après nettoyage\n",
    "validate_cleaned_data(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a3029-dfda-4aed-a516-efc9c75335d6",
   "metadata": {},
   "source": [
    "## Exportation des données nettoyées vers MongoDB partagée\n",
    "\n",
    "Les données nettoyées sont exportées dans des collections MongoDB distinctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9183b8c-77c2-4687-8f9e-1cc9b6b95fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer la colonne '_id' des données\n",
    "def remove_mongo_id(data):\n",
    "    \"\"\"\n",
    "    Supprime la colonne '_id' des données si elle existe.\n",
    "    \"\"\"\n",
    "    # Si la colonne '_id' existe, on la supprime\n",
    "    for record in data:\n",
    "        record.pop('_id', None)  # Supprime l'attribut _id si présent\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Exemple d'utilisation : avant d'exporter les données\n",
    "cleaned_data_no_id = remove_mongo_id(cleaned_data.to_dict(orient='records'))\n",
    "\n",
    "# Vérifier que l'_id est bien supprimé\n",
    "print(f\"Nombre de données après suppression de '_id': {len(cleaned_data_no_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb96ed3-ab00-49b6-a9ad-10f8b50ab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour exporter les données nettoyées vers MongoDB (après suppression de '_id')\n",
    "def export_cleaned_data_to_mongodb(data, collection_name, db_name='contracts_cleaned'):\n",
    "    try:\n",
    "        # Accéder à la collection MongoDB\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        # Insérer les données nettoyées\n",
    "        if isinstance(data, list):\n",
    "            collection.insert_many(data)\n",
    "        else:\n",
    "            collection.insert_one(data)\n",
    "        \n",
    "        print(f\"Données nettoyées exportées vers MongoDB dans la collection {collection_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exportation des données nettoyées vers MongoDB : {e}\")\n",
    "\n",
    "\n",
    "# Exemple d'utilisation : Exporter les données nettoyées sans '_id' vers MongoDB\n",
    "export_cleaned_data_to_mongodb(cleaned_data_no_id, 'contracts_cleaned_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac15c4c-64cc-4213-8b6b-05dc49a407c8",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Data Understanding</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e2dd04-8719-4c3b-aaaf-b1b7d3e3242b",
   "metadata": {},
   "source": [
    "Un contrat validé sur la plateforme Etherscan (ou une plateforme similaire de blockchain) est essentiellement un smart contract (contrat intelligent) qui a été vérifié publiquement sur la blockchain, permettant ainsi à n'importe qui de lire et d'interagir avec le code du contrat. Voici un résumé des principales informations que pourrait contenir un contrat validé :\n",
    "- Adresse du Contrat (Contract Address)\n",
    " L'adresse unique du contrat intelligent sur la blockchain Ethereum. C'est une chaîne de caractères qui identifie de manière unique ce contrat.\n",
    "- Nom du Contrat (Contract Name)\n",
    "Le nom donné au contrat lors de sa création. Il est souvent défini par les développeurs et peut donner des indications sur la fonctionnalité du contrat (par exemple, ERC20Token, VotingContract, etc.).\n",
    "- Version du Compilateur (Compiler Version)\n",
    "La version du compilateur Solidity utilisée pour compiler le contrat. Solidity est le langage de programmation utilisé pour écrire les contrats intelligents sur Ethereum.\n",
    "- Équilibre (Balance)\n",
    "Le montant d'ether (ETH) détenu par le contrat. Cela représente l'argent qui a été envoyé ou stocké dans le contrat.\n",
    "- Vérifié (Verified)\n",
    "Indique si le code source du contrat a été vérifié et publié sur la plateforme (comme Etherscan).\n",
    "## Exemple de Contenu d'un Contrat Vérifié sur Etherscan\n",
    "- Adresse du contrat : 0x1234567890abcdef1234567890abcdef12345678\n",
    "- Version du compilateur : v0.8.4\n",
    "- Équilibre : 1000 ETH\n",
    "- Vérifié : Oui:1 ,0:non\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c4318-7b7b-4da4-b47f-c027fb65b2b8",
   "metadata": {},
   "source": [
    "## Visualisation Data \n",
    "La visualisation des données est une étape clé pour mieux comprendre leur structure et extraire des insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fdd4c-5758-4283-a74b-5cf2a1824d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a21296-def6-426f-b9c4-9622ea1d526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les données nettoyées depuis MongoDB\n",
    "cleaned_data = import_from_mongodb('contracts_cleaned_data')\n",
    "\n",
    "# Convertir en DataFrame Pandas\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Afficher les 5 premières lignes pour vérifier\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394649a-5368-4963-b983-8e70e42009e3",
   "metadata": {},
   "source": [
    "##  Distribution des valeurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7bd83-1a58-4bf3-8d71-080d1f9fcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Équilibre'], bins=20, kde=True)\n",
    "plt.title(\"Distribution des soldes des contrats\")\n",
    "plt.xlabel(\"Équilibre\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899f01b-10be-4430-8f77-4bccd3c9faa6",
   "metadata": {},
   "source": [
    "## Répartition des contrats vérifiés et non vérifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec082b-e6d2-49e9-b1ce-184de0cec66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "df['Vérifié'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, cmap='coolwarm')\n",
    "plt.title(\"Répartition des contrats vérifiés et non vérifiés\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a209289-b33b-40eb-925a-4aa509dc7dd2",
   "metadata": {},
   "source": [
    "## Boxplot pour détecter les valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a1c71-26ed-4404-8e31-06383c0a4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=df['Équilibre'])\n",
    "plt.title(\"Détection des valeurs aberrantes dans les soldes des contrats\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f22da2-088c-486c-b282-7cce65a7bd66",
   "metadata": {},
   "source": [
    "## Automatiser le Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bbaf4-60b0-4ef2-bfa6-04c33b5d4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def connect_to_mongodb():\n",
    "    \"\"\"Établit une connexion à MongoDB.\"\"\"\n",
    "    connection_string = \"mongodb+srv://nasrhamza:drgzquMCEexvUYVV@cluster0.6pqb0.mongodb.net/\"\n",
    "    client = MongoClient(connection_string)\n",
    "    return client.due_diligence\n",
    "\n",
    "def fetch_etherscan_data(page_url):\n",
    "    \"\"\"Récupère les transactions depuis Etherscan.\"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        contracts = []\n",
    "        rows = soup.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                contracts.append({\n",
    "                    \"Adresse\": cols[0].text.strip(),\n",
    "                    \"Nom\": cols[1].text.strip(),\n",
    "                    \"Version\": cols[3].text.strip(),\n",
    "                    \"Équilibre\": cols[4].text.strip(),\n",
    "                    \"Vérifié\": cols[5].text.strip(),\n",
    "                    \"Date_Extraction\": datetime.now()\n",
    "                })\n",
    "        return contracts\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def export_to_mongodb(db, data, collection_name):\n",
    "    \"\"\"Exporte des données vers MongoDB.\"\"\"\n",
    "    collection = db[collection_name]\n",
    "    if isinstance(data, list):\n",
    "        collection.insert_many(data)\n",
    "    else:\n",
    "        collection.insert_one(data)\n",
    "\n",
    "def clean_data(db):\n",
    "    \"\"\"Nettoie les données récupérées depuis MongoDB.\"\"\"\n",
    "    raw_data = list(db.transactions_raw.find())\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    df = df.drop(columns=['_id'], errors='ignore')\n",
    "    df = df.dropna()\n",
    "    df[\"Équilibre\"] = pd.to_numeric(df[\"Équilibre\"], errors='coerce')\n",
    "    cleaned_data = df.to_dict(orient='records')\n",
    "    return cleaned_data\n",
    "\n",
    "def main():\n",
    "    db = connect_to_mongodb()\n",
    "    etherscan_url = \"https://etherscan.io/contractsVerified\"\n",
    "    data = fetch_etherscan_data(etherscan_url)\n",
    "    export_to_mongodb(db, data, 'transactions_raw')\n",
    "    cleaned_data = clean_data(db)\n",
    "    export_to_mongodb(db, cleaned_data, 'transactions_cleaned')\n",
    "    print(\"Pipeline exécuté avec succès !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
