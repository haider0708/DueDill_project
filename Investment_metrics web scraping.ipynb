{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "<!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><script>!function(){var d=document.documentElement.classList;d.remove('light','dark');d.add('light')}()</script><meta name=\"next-head-count\" content=\"3\"/><link rel=\"preconnect\" href=\"https://fonts.googleapis.com\"/><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin=\"true\"/><link href=\"/fonts/Codec-Pro/Codec-Pro-Regular.ttf\" rel=\"preload\" as=\"font\" crossorigin=\"anonymous\"/><link href=\"/fonts/Codec-Pro/Codec-Pro-Light.ttf\" rel=\"preload\" as=\"font\" crossorigin=\"anonymous\"/><link href=\"/fonts/Codec-Pro/Codec-Pro-Thin.ttf\" rel=\"preload\" as=\"font\" crossorigin=\"anonymous\"/><link href=\"/fonts/Codec-Pro/Codec-Pro-Bold.ttf\" rel=\"preload\" as=\"font\" crossorigin=\"anonymous\"/><link href=\"/fonts/Codec-Pro/Codec-Pro-Extrabold.ttf\" rel=\"preload\" as=\"font\" crossorigin=\"anonymous\"/><script>\n",
      "            (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-M675NCH');\n",
      "          </script><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin /><link rel=\"preload\" href=\"/_next/static/css/f582079db0b6c787.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/f582079db0b6c787.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js\"></script><script src=\"/_next/static/chunks/webpack-00dd84cff17b2633.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-5f4595e5518b5600.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-8db7d21a15d54ad1.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-254ed93749ab59b6.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/404-ec08e5a2b2e68b86.js\" defer=\"\"></script><script src=\"/_next/static/o2eUM-THQCLKcKd3x6WMY/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/o2eUM-THQCLKcKd3x6WMY/_ssgManifest.js\" defer=\"\"></script><style data-href=\"https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Courier+Prime&display=swap\">@font-face{font-family:'Bebas Neue';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/bebasneue/v10/JTUSjIg69CK48gW7PXooxW0.woff) format('woff')}@font-face{font-family:'Courier Prime';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/courierprime/v7/u-450q2lgwslOqpF_6gQ8kELWwU.woff) format('woff')}@font-face{font-family:'Bebas Neue';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/bebasneue/v10/JTUSjIg69CK48gW7PXoo9WdhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Bebas Neue';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/bebasneue/v10/JTUSjIg69CK48gW7PXoo9WlhyyTh89Y.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Courier Prime';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/courierprime/v7/u-450q2lgwslOqpF_6gQ8kELaw9pWs39pvnRPA.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Courier Prime';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/courierprime/v7/u-450q2lgwslOqpF_6gQ8kELawFpWs39pvk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id=\"__next\" data-reactroot=\"\"><div id=\"top-level\" class=\"relative min-h-screen overflow-hidden font-primary bg-[#FFFCF6] \"><main class=\"relative z-10\"><div class=\"flex h-screen w-full flex-col items-center justify-center\"><h1 class=\"-mt-24 text-xl font-bold\"><span class=\"text-3xl font-bold\">404</span> - Page Not Found</h1><button class=\"my-4 rounded-lg bg-primary-500 p-3 text-white duration-500 hover:scale-105\">Back to DefiPulse.com</button></div></main></div> </div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{}},\"page\":\"/404\",\"query\":{},\"buildId\":\"o2eUM-THQCLKcKd3x6WMY\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false,\"scriptLoader\":[]}</script><noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-M675NCH\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript></body></html>\n",
      "Erreur de décodage JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Les données ont été extraites et sauvegardées dans 'investment_metrics.csv'.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Liste des actifs à suivre (cryptos et actions)\n",
    "assets = ['BTC-USD', 'ETH-USD', 'AAPL', 'GOOG', 'MSFT']\n",
    "\n",
    "# Fonction pour récupérer les données depuis Yahoo Finance\n",
    "def get_yahoo_data(asset):\n",
    "    stock = yf.Ticker(asset)\n",
    "    hist = stock.history(period=\"1d\")\n",
    "    info = stock.info\n",
    "    \n",
    "    data = {\n",
    "        'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "        'Actif': asset,\n",
    "        'Type': 'Crypto' if 'USD' in asset else 'Stock',\n",
    "        'Prix actuel': hist['Close'].iloc[0],\n",
    "        'Variation journalière (%)': hist['Close'].pct_change().iloc[-1] * 100,\n",
    "        'Volume de transactions': hist['Volume'].iloc[0],\n",
    "        'Market Capitalization': info.get('marketCap', '-'),\n",
    "        'P/E Ratio': info.get('trailingPE', '-'),\n",
    "        'EPS': info.get('trailingEps', '-'),\n",
    "        'Dividend Yield': info.get('dividendYield', '-'),\n",
    "        'ROE': info.get('returnOnEquity', '-'),\n",
    "        'ROA': info.get('returnOnAssets', '-'),\n",
    "        'Beta': info.get('beta', '-'),\n",
    "        'Debt-to-Equity Ratio': info.get('debtToEquity', '-')\n",
    "    }\n",
    "    return data\n",
    "\n",
    "# Fonction pour récupérer les données depuis DeFi Pulse (pour les cryptos)\n",
    "def get_defi_pulse_data():\n",
    "    defi_url = \"https://defipulse.com/api/v1/defi/overview\"\n",
    "    response = requests.get(defi_url)\n",
    "    print(response.status_code)  # Vérifie si la requête a réussi (200)\n",
    "    print(response.text)  # Affiche le contenu brut de la réponse\n",
    "    try:\n",
    "        data = response.json()  # Essaie de décoder la réponse JSON\n",
    "    except ValueError as e:\n",
    "        print(\"Erreur de décodage JSON:\", e)\n",
    "        return []\n",
    "    return data\n",
    "\n",
    "# Fonction pour récupérer les données économiques depuis IMF (PIB, Inflation, etc.)\n",
    "def get_imf_data():\n",
    "    imf_url = \"https://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.KD.ZG?format=json\"\n",
    "    imf_data = requests.get(imf_url).json()\n",
    "    data = []\n",
    "    for country_data in imf_data[1]:\n",
    "        country = country_data['country']['value']\n",
    "        gdp_growth = country_data['value'] if country_data['value'] is not None else '-'\n",
    "        \n",
    "        # Exemple d'ajout d'autres indicateurs\n",
    "        data.append({\n",
    "            'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "            'Actif': country,\n",
    "            'Type': 'Economique',\n",
    "            'Prix actuel': '-',  # Non applicable ici\n",
    "            'Variation journalière (%)': '-',  # Non applicable ici\n",
    "            'Volume de transactions': '-',  # Non applicable ici\n",
    "            'Market Capitalization': '-',  # Non applicable ici\n",
    "            'P/E Ratio': '-',  # Non applicable ici\n",
    "            'EPS': '-',  # Non applicable ici\n",
    "            'Dividend Yield': '-',  # Non applicable ici\n",
    "            'ROE': '-',  # Non applicable ici\n",
    "            'ROA': '-',  # Non applicable ici\n",
    "            'Beta': '-',  # Non applicable ici\n",
    "            'Debt-to-Equity Ratio': '-',  # Non applicable ici\n",
    "            'Total Value Locked (TVL)': '-',  # Non applicable ici\n",
    "            'Supply Circulant': '-',  # Non applicable ici\n",
    "            'Hashrate': '-',  # Non applicable ici\n",
    "            'Gas Fees': '-',  # Non applicable ici\n",
    "            'Staking Yield': '-',  # Non applicable ici\n",
    "            'PIB (%)': gdp_growth,\n",
    "            'Inflation Rate': '-',  # Exemple d'ajout de données d'inflation\n",
    "            'Taux d’intérêt directeur': '-',  # Exemple\n",
    "            'Unemployment Rate': '-',  # Exemple\n",
    "            'Indice des prix à la consommation (CPI)': '-'  # Exemple\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Récupérer les données pour tous les actifs financiers\n",
    "data_list = []\n",
    "\n",
    "# Extraire les données de Yahoo Finance pour chaque actif\n",
    "for asset in assets:\n",
    "    data = get_yahoo_data(asset)\n",
    "    data_list.append(data)\n",
    "\n",
    "# Extraire les données DeFi Pulse\n",
    "defi_data = get_defi_pulse_data()\n",
    "data_list.extend(defi_data)\n",
    "\n",
    "# Extraire les données IMF (Economiques)\n",
    "imf_data = get_imf_data()\n",
    "data_list.extend(imf_data)\n",
    "\n",
    "# Créer un DataFrame avec toutes les données\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Sauvegarder dans un fichier CSV\n",
    "df.to_csv('investment_metrics.csv', index=False)\n",
    "\n",
    "print(\"Les données ont été extraites et sauvegardées dans 'investment_metrics.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_yahoo_data(asset):\n",
    "    stock = yf.Ticker(asset)\n",
    "    time.sleep(2)  # Attendre 2 secondes entre chaque requête\n",
    "    hist = stock.history(period=\"1d\")\n",
    "    info = stock.info\n",
    "    \n",
    "    if hist.empty:\n",
    "        return None  # Retourne None si aucune donnée disponible\n",
    "    \n",
    "    data = {\n",
    "        'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "        'Actif': asset,\n",
    "        'Type': 'Crypto' if 'USD' in asset else 'Stock',\n",
    "        'Prix actuel': hist['Close'].iloc[-1],\n",
    "        'Variation journalière (%)': hist['Close'].pct_change().iloc[-1] * 100,\n",
    "        'Volume de transactions': hist['Volume'].iloc[-1],\n",
    "        'Market Capitalization': info.get('marketCap', '-'),\n",
    "        'P/E Ratio': info.get('trailingPE', '-'),\n",
    "        'EPS': info.get('trailingEps', '-'),\n",
    "        'Dividend Yield': info.get('dividendYield', '-'),\n",
    "        'ROE': info.get('returnOnEquity', '-'),\n",
    "        'ROA': info.get('returnOnAssets', '-'),\n",
    "        'Beta': info.get('beta', '-'),\n",
    "        'Debt-to-Equity Ratio': info.get('debtToEquity', '-')\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n",
      "\n",
      "5 Failed downloads:\n",
      "['BTC-USD', 'ETH-USD', 'GOOG', 'AAPL', 'MSFT']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [(Adj Close, AAPL), (Adj Close, BTC-USD), (Adj Close, ETH-USD), (Adj Close, GOOG), (Adj Close, MSFT), (Close, AAPL), (Close, BTC-USD), (Close, ETH-USD), (Close, GOOG), (Close, MSFT), (High, AAPL), (High, BTC-USD), (High, ETH-USD), (High, GOOG), (High, MSFT), (Low, AAPL), (Low, BTC-USD), (Low, ETH-USD), (Low, GOOG), (Low, MSFT), (Open, AAPL), (Open, BTC-USD), (Open, ETH-USD), (Open, GOOG), (Open, MSFT), (Volume, AAPL), (Volume, BTC-USD), (Volume, ETH-USD), (Volume, GOOG), (Volume, MSFT)]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "yahoo_data = yf.download(assets, period=\"1d\")\n",
    "print(yahoo_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec AAPL: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "⚠️ Aucune donnée récupérée.\n"
     ]
    }
   ],
   "source": [
    "pip install requests[socks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lyna Bouzouita\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pysocks in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pysocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BTC-USD: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec BTC-USD: Missing dependencies for SOCKS support.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ETH-USD: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec ETH-USD: Missing dependencies for SOCKS support.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AAPL: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec AAPL: Missing dependencies for SOCKS support.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GOOG: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec GOOG: Missing dependencies for SOCKS support.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MSFT: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec MSFT: Missing dependencies for SOCKS support.\n",
      "⚠️ Aucune donnée récupérée.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration du proxy (remplace avec ton proxy si besoin)\n",
    "proxies = {\n",
    "    \"http\": \"socks5h://127.0.0.1:9050\",  # Exemple avec Tor\n",
    "    \"https\": \"socks5h://127.0.0.1:9050\"\n",
    "}\n",
    "\n",
    "# Configurer les variables d'environnement pour que toutes les requêtes utilisent le proxy\n",
    "os.environ['http_proxy'] = proxies['http']\n",
    "os.environ['https_proxy'] = proxies['https']\n",
    "\n",
    "assets = ['BTC-USD', 'ETH-USD', 'AAPL', 'GOOG', 'MSFT']\n",
    "\n",
    "def get_yahoo_data(asset, retries=5, delay=20):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            stock = yf.Ticker(asset)\n",
    "            time.sleep(2)  # Pause pour éviter le blocage\n",
    "            \n",
    "            hist = stock.history(period=\"1d\")\n",
    "            info = stock.info\n",
    "            \n",
    "            if hist.empty:\n",
    "                print(f\"⚠️ Aucune donnée pour {asset}.\")\n",
    "                return None  \n",
    "            \n",
    "            return {\n",
    "                'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "                'Actif': asset,\n",
    "                'Prix actuel': hist['Close'].iloc[-1],\n",
    "                'Volume': hist['Volume'].iloc[-1],\n",
    "                'MarketCap': info.get('marketCap', '-')\n",
    "            }\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                print(f\"Rate limit dépassé pour {asset}. Attente de {delay} sec...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"Erreur HTTP pour {asset}: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {asset}: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Récupération des données Yahoo Finance\n",
    "yahoo_data = [get_yahoo_data(asset) for asset in assets]\n",
    "yahoo_data = [d for d in yahoo_data if d]\n",
    "\n",
    "# Enregistrement des données\n",
    "if yahoo_data:\n",
    "    yahoo_df = pd.DataFrame(yahoo_data)\n",
    "    file_name = f\"yahoo_finance_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    yahoo_df.to_csv(file_name, index=False)\n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n",
    "else:\n",
    "    print(\"⚠️ Aucune donnée récupérée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_defi_pulse_data():\n",
    "    defi_url = \"https://defipulse.com/api/v1/defi/overview\"\n",
    "    response = requests.get(defi_url)\n",
    "    print(response.status_code)  # Vérifie si la requête a réussi (200)\n",
    "    print(response.text)  # Affiche le contenu brut de la réponse\n",
    "    try:\n",
    "        data = response.json()  # Essaie de décoder la réponse JSON\n",
    "    except ValueError as e:\n",
    "        print(\"Erreur de décodage JSON:\", e)\n",
    "        return []\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec BTC-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec ETH-USD: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec AAPL: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec AAPL: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec AAPL: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v10/finance/quoteSummary/AAPL?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=AAPL&crumb=Edge%3A+Too+Many+Requests (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Erreur avec AAPL: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec AAPL: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec GOOG: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "Erreur avec MSFT: Too Many Requests. Rate limited. Try after a while.\n",
      "⚠️ Aucune donnée récupérée.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Liste des actifs (tickers) à récupérer\n",
    "assets = ['BTC-USD', 'ETH-USD', 'AAPL', 'GOOG', 'MSFT']\n",
    "\n",
    "# Fonction pour récupérer les metrics d'investissement et les insights financiers\n",
    "def get_investment_metrics(asset, retries=5, delay=5):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            stock = yf.Ticker(asset)\n",
    "            info = stock.info  # Récupère toutes les informations financières\n",
    "\n",
    "            # Vérifier si les données sont disponibles\n",
    "            if not info:\n",
    "                print(f\"⚠️ Aucune donnée pour {asset}.\")\n",
    "                return None\n",
    "\n",
    "            # Extraire les métriques financières importantes\n",
    "            return {\n",
    "                'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "                'Actif': asset,\n",
    "                'MarketCap': info.get('marketCap', '-'),\n",
    "                'PE Ratio': info.get('trailingPE', '-'),\n",
    "                'Dividend Yield': info.get('dividendYield', '-'),\n",
    "                'Revenue': info.get('totalRevenue', '-'),\n",
    "                'NetIncome': info.get('netIncomeToCommon', '-'),\n",
    "                'ROE': info.get('returnOnEquity', '-'),\n",
    "                'Revenue Growth': info.get('revenueGrowth', '-'),\n",
    "                'Current Price': info.get('currentPrice', '-')\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {asset}: {e}\")\n",
    "            time.sleep(delay)  # Attendre avant de réessayer\n",
    "    return None\n",
    "\n",
    "# Récupération des données pour tous les actifs\n",
    "investment_data = []\n",
    "for asset in assets:\n",
    "    data = get_investment_metrics(asset)\n",
    "    if data:\n",
    "        investment_data.append(data)\n",
    "    time.sleep(2)  # Délai entre les requêtes pour éviter les limitations\n",
    "\n",
    "# Enregistrement des données dans un fichier CSV\n",
    "if investment_data:\n",
    "    investment_df = pd.DataFrame(investment_data)\n",
    "    file_name = f\"investment_metrics_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    investment_df.to_csv(file_name, index=False)\n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n",
    "else:\n",
    "    print(\"⚠️ Aucune donnée récupérée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur DefiLlama: Expecting value: line 1 column 1 (char 0)\n",
      "Aperçu des données collectées :\n",
      "      Date   Inflation_Index TVL_USD\n",
      "0  2020-01  118.305202115975     NaN\n",
      "1  2020-02  118.629431497944     NaN\n",
      "2  2020-03  118.371240349361     NaN\n",
      "3  2020-04   117.57969874642     NaN\n",
      "4  2020-05  117.581991740635     NaN\n",
      "✅ Données enregistrées : investment_metrics_2025-02-19.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Récupération des données macroéconomiques de l'IMF\n",
    "# ----------------------------\n",
    "def get_imf_data():\n",
    "    imf_url = \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/IFS/M.US.PCPI_IX?startPeriod=2020&endPeriod=2024\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(imf_url)\n",
    "        data = response.json()\n",
    "        series = data['CompactData']['DataSet']['Series']\n",
    "        records = []\n",
    "        \n",
    "        for item in series['Obs']:\n",
    "            records.append({\n",
    "                'Date': item['@TIME_PERIOD'],\n",
    "                'Inflation_Index': item['@OBS_VALUE']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur IMF: {e}\")\n",
    "        return pd.DataFrame(columns=['Date', 'Inflation_Index'])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Récupération des données DeFi via DefiLlama\n",
    "# ----------------------------\n",
    "def get_defi_llama_data():\n",
    "    defi_url = \"https://api.llama.fi/tvl/defi\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(defi_url)\n",
    "        data = response.json()\n",
    "        \n",
    "        records = [{\n",
    "            'Date': datetime.today().strftime('%Y-%m-%d'),\n",
    "            'TVL_USD': data.get('totalLiquidityUSD', 'N/A')\n",
    "        }]\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur DefiLlama: {e}\")\n",
    "        return pd.DataFrame(columns=['Date', 'TVL_USD'])\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    imf_df = get_imf_data()\n",
    "    defi_df = get_defi_llama_data()\n",
    "    \n",
    "    final_df = pd.concat([imf_df, defi_df], ignore_index=True)\n",
    "    print(\"Aperçu des données collectées :\")\n",
    "    print(final_df.head())\n",
    "    \n",
    "    file_name = f\"investment_metrics_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    final_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Chemin du fichier : c:\\Users\\Lyna Bouzouita\\AppData\\Local\\Programs\\Microsoft VS Code\\investment_metrics_2025-02-19.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_name = f\"investment_metrics_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "file_path = os.path.abspath(file_name)\n",
    "\n",
    "print(f\"📂 Chemin du fichier : {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur DefiLlama: 'str' object cannot be interpreted as an integer\n",
      "Aperçu des données collectées :\n",
      "  Source     Date        Indicator             Value\n",
      "0    IMF  1980-01  Inflation_Index  35.6789899819083\n",
      "1    IMF  1980-02  Inflation_Index  36.1834487091589\n",
      "2    IMF  1980-03  Inflation_Index   36.733767320705\n",
      "3    IMF  1980-04  Inflation_Index  37.1465062793647\n",
      "4    IMF  1980-05  Inflation_Index  37.5133853537288\n",
      "Nombre total de lignes : 540\n",
      "✅ Données enregistrées : investments_metrics_2025-02-19.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyna Bouzouita\\AppData\\Local\\Temp\\ipykernel_19848\\3563727275.py:45: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  'Date': datetime.utcfromtimestamp(item['date']).strftime('%Y-%m-%d'),\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Récupération des données macroéconomiques de l'IMF (1980-2024)\n",
    "# ----------------------------\n",
    "def get_imf_data():\n",
    "    imf_url = \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/IFS/M.US.PCPI_IX?startPeriod=1980&endPeriod=2024\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(imf_url)\n",
    "        data = response.json()\n",
    "        series = data['CompactData']['DataSet']['Series']\n",
    "        records = []\n",
    "        \n",
    "        for item in series['Obs']:\n",
    "            records.append({\n",
    "                'Source': 'IMF',\n",
    "                'Date': item['@TIME_PERIOD'],\n",
    "                'Indicator': 'Inflation_Index',\n",
    "                'Value': item['@OBS_VALUE']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur IMF: {e}\")\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Récupération de l'historique TVL via DefiLlama\n",
    "# ----------------------------\n",
    "def get_defi_llama_data():\n",
    "    defi_url = \"https://api.llama.fi/charts\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(defi_url)\n",
    "        data = response.json()\n",
    "        records = []\n",
    "        \n",
    "        for item in data:\n",
    "            records.append({\n",
    "                'Source': 'DefiLlama',\n",
    "                'Date': datetime.utcfromtimestamp(item['date']).strftime('%Y-%m-%d'),\n",
    "                'Indicator': 'TVL_USD',\n",
    "                'Value': item['totalLiquidityUSD']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur DefiLlama: {e}\")\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    imf_df = get_imf_data()\n",
    "    defi_df = get_defi_llama_data()\n",
    "    \n",
    "    final_df = pd.concat([imf_df, defi_df], ignore_index=True)\n",
    "    print(\"Aperçu des données collectées :\")\n",
    "    print(final_df.head())\n",
    "    print(f\"Nombre total de lignes : {len(final_df)}\")\n",
    "    \n",
    "    file_name = f\"investments_metrics_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    final_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Defi Pulse: 'NoneType' object has no attribute 'find_all'\n",
      "Aperçu des données collectées :\n",
      "  Source     Date        Indicator             Value\n",
      "0    IMF  1980-01  Inflation_Index  35.6789899819083\n",
      "1    IMF  1980-02  Inflation_Index  36.1834487091589\n",
      "2    IMF  1980-03  Inflation_Index   36.733767320705\n",
      "3    IMF  1980-04  Inflation_Index  37.1465062793647\n",
      "4    IMF  1980-05  Inflation_Index  37.5133853537288\n",
      "Nombre total de lignes : 540\n",
      "✅ Données enregistrées : investments_metrics2_2025-02-19.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Récupération des données macroéconomiques de l'IMF (1980-2024)\n",
    "# ----------------------------\n",
    "def get_imf_data():\n",
    "    imf_url = \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/IFS/M.US.PCPI_IX?startPeriod=1980&endPeriod=2024\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(imf_url)\n",
    "        data = response.json()\n",
    "        series = data['CompactData']['DataSet']['Series']\n",
    "        records = []\n",
    "        \n",
    "        for item in series['Obs']:\n",
    "            records.append({\n",
    "                'Source': 'IMF',\n",
    "                'Date': item['@TIME_PERIOD'],\n",
    "                'Indicator': 'Inflation_Index',\n",
    "                'Value': item['@OBS_VALUE']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur IMF: {e}\")\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Récupération de l'historique TVL via Defi Pulse (Web Scraping)\n",
    "# ----------------------------\n",
    "def get_defi_pulse_data():\n",
    "    defi_url = \"https://defipulse.com/\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(defi_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Example scraping logic (adjust according to the actual page structure)\n",
    "        # Scraping TVL data and dates\n",
    "        records = []\n",
    "        # Assuming TVL data is in a table or a section on the page (this needs to be adjusted based on actual site structure)\n",
    "        data_section = soup.find('section', {'class': 'tvl-data'})  # Replace with the correct class or tag\n",
    "        \n",
    "        for row in data_section.find_all('div', {'class': 'data-row'}):  # Adjust tag/class as needed\n",
    "            date = row.find('span', {'class': 'date'}).text.strip()  # Adjust the selector\n",
    "            tvl_value = row.find('span', {'class': 'value'}).text.strip()  # Adjust the selector\n",
    "            \n",
    "            records.append({\n",
    "                'Source': 'Defi Pulse',\n",
    "                'Date': date,\n",
    "                'Indicator': 'TVL_USD',\n",
    "                'Value': tvl_value\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur Defi Pulse: {e}\")\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    imf_df = get_imf_data()\n",
    "    defi_pulse_df = get_defi_pulse_data()\n",
    "    \n",
    "    final_df = pd.concat([imf_df, defi_pulse_df], ignore_index=True)\n",
    "    print(\"Aperçu des données collectées :\")\n",
    "    print(final_df.head())\n",
    "    print(f\"Nombre total de lignes : {len(final_df)}\")\n",
    "    \n",
    "    file_name = f\"investments_metrics2_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    final_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Defi Pulse: 'NoneType' object has no attribute 'find_all'\n",
      "Aperçu des données collectées :\n",
      "Empty DataFrame\n",
      "Columns: [Source, Date, Indicator, Value]\n",
      "Index: []\n",
      "Nombre total de lignes : 0\n",
      "✅ Données enregistrées : defi_pulse_data_2025-02-19.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Récupération de l'historique TVL via Defi Pulse (Web Scraping)\n",
    "# ----------------------------\n",
    "def get_defi_pulse_data():\n",
    "    defi_url = \"https://defipulse.com/\"  # URL de Defi Pulse\n",
    "    \n",
    "    try:\n",
    "        # Récupération de la page HTML\n",
    "        response = requests.get(defi_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Liste pour stocker les données extraites\n",
    "        records = []\n",
    "        \n",
    "        # Exemple de scraping - ajustez cette section en fonction de la structure de la page\n",
    "        # Nous allons chercher une section ou un tableau contenant des informations sur le TVL\n",
    "        data_section = soup.find('section', {'class': 'tvl-data'})  # Remplacer par la bonne classe ou tag\n",
    "        \n",
    "        # Parcours des éléments contenant les données TVL\n",
    "        for row in data_section.find_all('div', {'class': 'data-row'}):  # Remplacer par la bonne classe ou tag\n",
    "            date = row.find('span', {'class': 'date'}).text.strip()  # Extraire la date\n",
    "            tvl_value = row.find('span', {'class': 'value'}).text.strip()  # Extraire la valeur du TVL\n",
    "            \n",
    "            # Ajouter les informations dans la liste\n",
    "            records.append({\n",
    "                'Source': 'Defi Pulse',\n",
    "                'Date': date,\n",
    "                'Indicator': 'TVL_USD',\n",
    "                'Value': tvl_value\n",
    "            })\n",
    "        \n",
    "        # Retourner les données sous forme de DataFrame\n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur Defi Pulse: {e}\")\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    defi_pulse_df = get_defi_pulse_data()  # Récupérer les données de Defi Pulse\n",
    "    \n",
    "    # Afficher un aperçu des données collectées\n",
    "    print(\"Aperçu des données collectées :\")\n",
    "    print(defi_pulse_df.head())\n",
    "    print(f\"Nombre total de lignes : {len(defi_pulse_df)}\")\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier CSV\n",
    "    file_name = f\"defi_pulse_data_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    defi_pulse_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/a0/9f/34d0ec09b0dd6fb7b08b93eb4b7b80049e0b9db0ba7f81ad814c9be78b8f/selenium-4.28.1-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/c9/55/c4d9bea8b3d7937901958f65124123512419ab0eb73695e5f382521abbfb/trio-0.29.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/d3/b9/b07ec357ba125ad26e1c07781b9d7f0414af85ad76e0d73617ddb5ce041c/trio_websocket-0.12.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sortedcontainers from https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.5 MB 825.8 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/9.5 MB 939.4 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.2/9.5 MB 984.6 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/9.5 MB 958.4 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/9.5 MB 983.0 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/9.5 MB 1.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/9.5 MB 1.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/9.5 MB 1.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.5/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/9.5 MB 1.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/9.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.7/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.9/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.9/9.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.2/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.2/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.4/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.4/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.5/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.5/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.7/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.7/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.9/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.9/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.0/9.5 MB 1.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.0/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.2/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.2/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.3/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.3/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.4/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.4/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.5/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.5/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.8/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.8/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 2.9/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 2.9/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.0/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.0/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.1/9.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.1/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.2/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.2/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.3/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.3/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.4/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.4/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.5/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.5/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.6/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.6/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.7/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.7/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.8/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.8/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.0/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.0/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.1/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.1/9.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.2/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.2/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.3/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.3/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.4/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.4/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.5/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.5/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.6/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.6/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.7/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.7/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.8/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.8/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.9/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.9/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.0/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.0/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.1/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.1/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.3/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.3/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.4/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.5/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.6/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.6/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.7/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.7/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.7/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.8/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.8/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.9/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.0/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.0/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.1/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.1/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.2/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.2/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.3/9.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.3/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.4/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.4/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.5/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.5/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.6/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.6/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.7/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.7/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.9/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.9/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.0/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.0/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.1/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.1/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.2/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.2/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.3/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.3/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.4/9.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.4/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.5/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.5/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.6/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.7/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.7/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.8/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.8/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.9/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.9/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.0/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.0/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.1/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.2/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.2/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.3/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.3/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.5/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.5/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.8/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.8/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.1/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.1/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "   ---------------------------------------- 0.0/492.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/492.9 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 92.2/492.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 143.4/492.9 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 194.6/492.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 245.8/492.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 286.7/492.9 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 337.9/492.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 389.1/492.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 440.3/492.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  491.5/492.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 492.9/492.9 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.12.1-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.1 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from requests->webdriver-manager) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lyna bouzouita\\appdata\\roaming\\python\\python312\\site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Defi Pulse: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00C374A3+25091]\n",
      "\t(No symbol) [0x00BBDC04]\n",
      "\t(No symbol) [0x00A9B373]\n",
      "\t(No symbol) [0x00ADF4DC]\n",
      "\t(No symbol) [0x00ADF65B]\n",
      "\t(No symbol) [0x00B1D8E2]\n",
      "\t(No symbol) [0x00B01F54]\n",
      "\t(No symbol) [0x00B1B49E]\n",
      "\t(No symbol) [0x00B01CA6]\n",
      "\t(No symbol) [0x00AD31D5]\n",
      "\t(No symbol) [0x00AD435D]\n",
      "\tGetHandleVerifier [0x00F307C3+3142947]\n",
      "\tGetHandleVerifier [0x00F41A2B+3213195]\n",
      "\tGetHandleVerifier [0x00F3C412+3191154]\n",
      "\tGetHandleVerifier [0x00CD8720+685184]\n",
      "\t(No symbol) [0x00BC6E1D]\n",
      "\t(No symbol) [0x00BC3E18]\n",
      "\t(No symbol) [0x00BC3FB6]\n",
      "\t(No symbol) [0x00BB66F0]\n",
      "\tBaseThreadInitThunk [0x757D5D49+25]\n",
      "\tRtlInitializeExceptionChain [0x77BECEBB+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77BECE41+561]\n",
      "\n",
      "Aperçu des données collectées :\n",
      "Empty DataFrame\n",
      "Columns: [Source, Date, Indicator, Value]\n",
      "Index: []\n",
      "Nombre total de lignes : 0\n",
      "✅ Données enregistrées : defi_pulse_data3_2025-02-19.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Récupération de l'historique TVL via Defi Pulse (Selenium)\n",
    "# ----------------------------\n",
    "def get_defi_pulse_data():\n",
    "    # Configuration du Service et du WebDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = Options()\n",
    "    options.headless = False  # Garder True pour exécuter sans ouvrir la fenêtre du navigateur\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    defi_url = \"https://defipulse.com/\"\n",
    "    \n",
    "    try:\n",
    "        driver.get(defi_url)\n",
    "        \n",
    "        # Attendre que l'élément contenant les données TVL soit visible\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'chart-item')]\")))\n",
    "        \n",
    "        print(\"Page complètement chargée\")\n",
    "        \n",
    "        # Attendre encore un peu pour s'assurer que tous les éléments ont été chargés\n",
    "        time.sleep(5)\n",
    "        \n",
    "        records = []\n",
    "        \n",
    "        # Sélectionner les éléments contenant les informations\n",
    "        tvl_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'chart-item')]\")\n",
    "        \n",
    "        if not tvl_elements:\n",
    "            print(\"Aucun élément trouvé !\")\n",
    "        \n",
    "        for item in tvl_elements:\n",
    "            try:\n",
    "                # Ajustez ces XPaths en fonction de la structure exacte de la page\n",
    "                date = item.find_element(By.XPATH, \".//div[contains(@class, 'date')]\").text.strip()\n",
    "                tvl_value = item.find_element(By.XPATH, \".//div[contains(@class, 'value')]\").text.strip()\n",
    "                \n",
    "                # Impression pour vérifier les données extraites\n",
    "                print(f\"Date: {date}, TVL: {tvl_value}\")\n",
    "                \n",
    "                records.append({\n",
    "                    'Source': 'Defi Pulse',\n",
    "                    'Date': date,\n",
    "                    'Indicator': 'TVL_USD',\n",
    "                    'Value': tvl_value\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur d'extraction dans un élément : {e}\")\n",
    "        \n",
    "        driver.quit()  # Fermer le navigateur après extraction\n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur Defi Pulse: {e}\")\n",
    "        driver.quit()\n",
    "        return pd.DataFrame(columns=['Source', 'Date', 'Indicator', 'Value'])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    defi_pulse_df = get_defi_pulse_data()  # Récupérer les données de Defi Pulse\n",
    "    \n",
    "    # Afficher un aperçu des données collectées\n",
    "    print(\"Aperçu des données collectées :\")\n",
    "    print(defi_pulse_df.head())\n",
    "    print(f\"Nombre total de lignes : {len(defi_pulse_df)}\")\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier CSV\n",
    "    file_name = f\"defi_pulse_data3_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "    defi_pulse_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"✅ Données enregistrées : {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Récupération des données pour AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Aucune donnée trouvée pour AAPL.\n",
      "⚠️ Le fichier est vide, aucune donnée récupérée.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Fonction pour récupérer les données avec une pause pour éviter le blocage\n",
    "# ----------------------------\n",
    "def get_yahoo_finance_data(ticker, start_date, end_date):\n",
    "    try:\n",
    "        print(f\"📊 Récupération des données pour {ticker}...\")\n",
    "        time.sleep(5)  # Attendre 5 secondes entre chaque requête pour éviter le blocage\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=True)\n",
    "        \n",
    "        if data.empty:\n",
    "            print(f\"⚠️ Aucune donnée trouvée pour {ticker}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Ajouter des colonnes supplémentaires\n",
    "        data['Source'] = 'Yahoo Finance'\n",
    "        data['Indicator'] = 'Stock_Price'\n",
    "        data['Date'] = data.index.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Réorganiser les colonnes\n",
    "        data = data[['Source', 'Date', 'Indicator', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "        \n",
    "        print(\"✅ Données collectées avec succès !\")\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur Yahoo Finance: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Exécution et sauvegarde\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    #ticker = 'AAPL'  # Apple\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-12-31'\n",
    "\n",
    "    yahoo_data = get_yahoo_finance_data(ticker, start_date, end_date)\n",
    "\n",
    "    if not yahoo_data.empty:\n",
    "        file_name = f\"yahoo_finance_data_{ticker}_{datetime.today().strftime('%Y-%m-%d')}.csv\"\n",
    "        yahoo_data.to_csv(file_name, index=False)\n",
    "        print(f\"✅ Données enregistrées : {file_name}\")\n",
    "    else:\n",
    "        print(\"⚠️ Le fichier est vide, aucune donnée récupérée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données enregistrées : apple_stock_data_2025-02-19.csv\n",
      "               Open     High      Low    Close   Volume\n",
      "1999-11-01  80.0000  80.6900  77.3700  77.6200  2487300\n",
      "1999-11-02  78.0000  81.6900  77.3100  80.2500  3564600\n",
      "1999-11-03  81.6200  83.2500  81.0000  81.5000  2932700\n",
      "1999-11-04  82.0600  85.3700  80.6200  83.6200  3384700\n",
      "1999-11-05  84.6200  88.3700  84.0000  88.3100  3721500\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Remplace par ta clé API Alpha Vantage\n",
    "API_KEY = \"VOTRE_CLE_API\"\n",
    "SYMBOL = \"AAPL\"\n",
    "URL = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={SYMBOL}&apikey={API_KEY}&outputsize=full\"\n",
    "\n",
    "# Requête à l'API\n",
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if \"Time Series (Daily)\" in data:\n",
    "        df = pd.DataFrame.from_dict(data[\"Time Series (Daily)\"], orient=\"index\")\n",
    "        df.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        # Sauvegarde en CSV\n",
    "        filename = f\"apple_stock_data_{time.strftime('%Y-%m-%d')}.csv\"\n",
    "        df.to_csv(filename)\n",
    "        print(f\"✅ Données enregistrées : {filename}\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"❌ Erreur : Données introuvables dans la réponse API.\")\n",
    "else:\n",
    "    print(f\"❌ Erreur HTTP {response.status_code} lors de l'accès à l'API.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
